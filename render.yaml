services:
  - type: web
    name: gpt-oss-api
    runtime: docker
    dockerfilePath: Dockerfile
    envVars:
      - key: PORT
        value: 8000
    plan: starter
    # Force stub backend to avoid torch dependency issues
    startCommand: "python -m gpt_oss.responses_api.serve --port $PORT --inference-backend stub"
